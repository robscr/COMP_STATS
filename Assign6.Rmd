---
title: "Assignment 6"
output: html_notebook
---

### Robert Scriba 22989793
```{r, quietly=TRUE}
library(magicaxis)
library(cooltools)
library(pracma)
library(data.table)
library(ggplot2)
library(devtools)
library(rcosmo)
library(hyper.fit)
library(LaplacesDemon)
library(ggplot2)
library(cubature)
```

## Question 1
```{r}
data <- fread("hiddenscales.csv")
```


```{r}
distancecount = function(x, y=NULL, dr, rmax) {

  nx = dim(x)[1]
  ny = dim(y)[1]
  nr = round(rmax/dr)+1
  count = array(0,nr)

  if (is.null(y)) {
    count[1] = nx # number of pairs i-i
    for (i in seq(nx-1)) {
      for (j in seq(i+1,nx)) {
        d = sqrt(sum((x[i,]-x[j,])^2))
        if (d<=rmax) {
          index = round(d/dr)+1
          count[index] = count[index]+1
        }
      }
    }
  } else {
    ny = dim(y)[1]
    for (i in seq(nx)) {
      for (j in seq(ny)) {
        d = sqrt(sum((x[i,]-y[j,])^2))
        if (d<=rmax) {
          index = round(d/dr)+1
          count[index] = count[index]+1
        }
      }
    }
  }

  return(count)
}

two.point.estimator.landy.szalay = function(D,R,dr=0.01) {

  # D: n-by-d matrix with d-dimensional positions of the observed point set
  # R: m-by-d matrix with d-dimensional positions of the random point set

  # convert data frames into matrices
  D = as.matrix(D)
  R = as.matrix(R)

  # determine size of data
  nD = dim(D)[1]
  nR = dim(R)[1]
  d = dim(D)[2]
  if (dim(R)[2]!=d) stop('D and R must have the same number of rows.')

  # determine maximal possible distance
  rmax = 0
  for (i in seq(d)) {
    minval = min(min(D[,i]),min(R[,i]))
    maxval = max(max(D[,i]),max(R[,i]))
    rmax = rmax+(maxval-minval)^2
  }
  rmax = sqrt(rmax)
  # rmax=2*3.8 rmax=0.1
  # count pairs
  DD = distancecount(D,dr=dr,rmax=rmax)
  RR = distancecount(R,dr=dr,rmax=rmax)
  DR = distancecount(D,R,dr=dr,rmax=rmax)

  # shell radii
  r = seq(0,length(DD)-1)*dr

  # compute L-S estimator
  nDD = nD*(nD-1)/2
  nRR = nR*(nR-1)/2
  nDR = nD*nR
  xi = (DD/nDD-2*DR/nDR)/RR*nRR+1
  err = sqrt(DD*(nRR/nDD/RR)^2+4*DR*(nRR/nDR/RR)^2+RR*((DD/nDD-2*DR/nDR)/RR^2*nRR)^2)
  # err = xi^0.5
  xi[RR==0 | DD==0] = err[RR==0 | DD==0] = NA

  # return results
  return(list(r=r, xi=xi, err=err))

}
```


```{r}
D<-data

# Generate random points
generate_random_points <- function(num_points, rmin, rmax) {
  points <- matrix(NA, ncol = 3, nrow = num_points)
  count <- 0

  while (count < num_points) {
    x <- runif(1, -rmax, rmax)
    y <- runif(1, -rmax, rmax)
    z <- runif(1, -rmax, rmax)
    distance <- sqrt(x^2 + y^2 + z^2)

    if (distance >= rmin && distance <= rmax) {
      count <- count + 1
      points[count, ] <- c(x, y, z)
    }
  }

  return(points)
}

# Generate random points
R <- generate_random_points(2000, 3.7, 3.8)


ls = two.point.estimator.landy.szalay(D,R,dr=0.001)
magplot(ls$r,ls$xi,pch=20,cex=1,ylim=c(-10,10))
magerr(ls$r,ls$xi,ylo=ls$err)
abline(h=0,lty=2)
```
```{r} 
# ls$r[order(ls$xi, decreasing = TRUE)[1:2]]
# ls$xi[order(ls$xi, decreasing = TRUE)[1:2]]

top2<-ls$r[order(ls$xi-ls$err, decreasing = TRUE)[1:2]]
# ls$xi[order(ls$xi-ls$err, decreasing = TRUE)[1:2]]

cat("The clear stand out points for a and b are: ",top2[1], "and", top2[2])
```


## Question 2
#### 2a.
```{r}
filename <- "L210N1536.bin"
density_data <- loadbin(filename, c(128, 128, 128), signed = TRUE)
```


```{r}
# Set the color scale and aspect ratio
par(pty = 's')

color_scale <- gray(((1+density_data[1,,])^0.2)/(max((1+density_data[1,,])^0.2)))

image(density_data[1,,], col = color_scale, xlab = "X", ylab = "Y")

```

#### 2b.

```{r}
L = 210
N = 128
dr = L / N

delta_k = dft(density_data)

wd <- function(x) {
  ifelse(x == 0, 1, sin(x) / x)
}

# Initialize variables
r_values = seq(0, 20, dr)  # Create a sequence of r values from 0 to 20Mpc/h
xi_values = numeric(length(r_values))  # Initialize an empty vector for ξ(r) values

# Loop over each r value
for (r_index in 1:length(r_values)) {
  r = r_values[r_index]
  result_sum = 0

  # Loop over each dimension (x1, x2, x3)
  for (x1 in 1:N) {
    for (x2 in 1:N) {
      for (x3 in 1:N) {
        k = 2 * pi * sqrt((x1 - 64)^2 + (x2 - 64)^2 + (x3 - 64)^2) / L
        result_sum = result_sum + wd(k * r) * abs(delta_k[x1, x2, x3])^2
      }
    }
  }

  xi_values[r_index] = result_sum
}

# Plot ξ(r) in a log-log plot
plot(r_values, xi_values, log = "xy", type = "l", xlab = "r (Mpc/h)", ylab = "ξ(r)")

```



#### 2c.
```{r}
# Fit a straight line in log-log space
log_r = log(r_values)[-1]  # Take the natural logarithm of r
log_xi = log(xi_values)[-1]  # Take the natural logarithm of ξ(r)

log_data <- cbind(log_r,log_xi)

# Fit the line using hyper.fit
fit <- hyper.fit(log_data)

# Plot the line on top of the points
plot(log_r, log_xi, col = "blue", xlab = "r (Mpc/h)", ylab = "ξ(r)")


lines(log_r, fit$fit$par[1] * log_r + fit$fit$par[2], col = "red", lwd = 2)  # Plot the fitted line

# Print the results
cat("Slope (Power Law Index):", round(fit$fit$par[1], 6), "\n")
cat("1-σ Uncertainty:", round(sqrt(fit$fit$Covar[1,1]), 6), "\n")


```



## Question 3
```{r}
# Load the quoson data
quoson_data <- read.csv("quosons.csv")
```


#### 3a.
```{r}
qa <- as.matrix(quoson_data)
sphereplot(qa, n=500, projection='mollweide',theta0 = 0, phi0 = pi/2)

```


#### 3b.
```{r}
# Define the spherical harmonic function
spherefun <- function(theta0, phi0, data) {
  # Extract theta and phi from the data 
  theta <- data$theta
  phi <- data$phi
  
  Y1 = function(m,theta,phi) sphericalharmonics(1,m,cbind(theta,phi))
  
  Yd = cos(theta0)*Y1(0,theta,phi)+ sin(theta0)*(cos(phi0)*Y1(1,theta,phi)+sin(phi0)*Y1(-1,theta,phi))
  
  return(Yd)
}

# Define the log-likelihood function for MLE
log_likelihood <- function(parameters, data) {
  a <- parameters[1]
  theta0 <- parameters[2]
  phi0 <- parameters[3]
  
  # Calculate log-likelihood using the given probability density function
  log_likelihood_value <- sum(log(1/(4*pi) + a * spherefun(theta0, phi0, data)))
  
  return(log_likelihood_value)  
}


# Initial parameter values
initial_params <- c(0.045, pi/2, pi)

# Bounds for optimization
lower_bounds <- c(0, 0, 0)
upper_bounds <- c(0.09, pi, 2 * pi)

# Run the optimization using "L-BFGS-B" method
optimal_params <- optim(par = initial_params, fn = log_likelihood, data = quoson_data,
                        method = "L-BFGS-B", lower = lower_bounds, upper = upper_bounds,control=list(fnscale=-1))$par

# Display the MLE solution
cat("MLE Solution:\n")
cat("a:", round(optimal_params[1], 6), "\n")
cat("theta0:", round(optimal_params[2], 5), "\n")
cat("phi0:", round(optimal_params[3], 5), "\n")

```


#### 3c.
```{r}
# Define the log-likelihood function for MLE
log_posterior <- function(parameters, data) {
  a <- parameters[1]
  theta0 <- parameters[2]
  phi0 <- parameters[3]
  prior_a = 0
  
  if (a >= 0 && a <= 0.09) {
    prior_a = 1/0.09
  }

  
  # Calculate log-likelihood using the given probability density function
  log_posterior <- sum(log((1/(4*pi) + a * spherefun(theta0, phi0, data))*prior_a))
  
  return(log_posterior)
}


# Initial parameter values
initial_params <- c(0.045, pi/2, pi)

# Bounds for optimization
lower_bounds <- c(0, 0, 0)
upper_bounds <- c(0.09, pi, 2 * pi)

# Run the optimization using "L-BFGS-B" method
map_optimal_params <- optim(par = initial_params, fn = log_posterior, data = quoson_data,
                        method = "L-BFGS-B", lower = lower_bounds, upper = upper_bounds,control=list(fnscale=-1))$par

# Display the MLE solution
cat("MAP Solution:\n")
cat("a:", round(map_optimal_params[1], 6), "\n")
cat("theta0:", round(map_optimal_params[2], 5), "\n")
cat("phi0:", round(map_optimal_params[3], 5), "\n")

```

#### 3d.
```{r}
set.seed(1)
Data_0 = list(data=quoson_data, mon.names='', parm.names=c('a', 'theta', 'phi'), N=nrow(quoson_data))

Model_coin = function(parm, data) {
  parm[1] = interval(parm[1], 0.0, 0.09)
  parm[2] = interval(parm[2], 0, pi)
  parm[3] = interval(parm[3], 0, 2*pi)
  val.prior = 0
  LL = log_posterior(parm,data$data)
  LP = LL+val.prior
  return(list(LP=LP, Dev=-2*LL, Monitor=1, yhat=1, parm=parm))
}

estimated_params = c(0.06, pi/2, pi)
output_0 = LaplacesDemon(Model_coin, Data_0, Initial.Values=estimated_params, Algorithm='CHARM',
Iterations=1e4, Thinning = 10, Status = Inf)
```

```{r}
magtri(output_0$Posterior1)
magtri(output_0$Posterior2)
```
```{r}
output_0$Summary1
```



#### 3e.


```{r}
# Log-likelihood of the data for the dipole model
# log_posterior_dipole <- log_posterior(optimal_params, quoson_data)

log_posterior_dipole <-log_posterior(c(0.03053508,2.84332958,3.30001421), quoson_data)

# Log-likelihood of the data for the monopole model (no parameters)
log_posterior_monopole <- log(nrow(quoson_data)/ (4 * pi))


bf = exp(log_posterior_monopole - log_posterior_dipole)

bf

```



